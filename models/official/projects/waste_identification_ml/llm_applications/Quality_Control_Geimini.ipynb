{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3psNACvJS8kc"
      },
      "source": [
        "# Annotation Quality Control using Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1ckBQ3IUQ5h"
      },
      "source": [
        "Welcome to this Colab Notebook, designed to help you analyze and verify instance segmentation annotations stored in COCO JSON format. Accurate annotations are critical for training high-performance computer vision models, and this notebook provides a quality assurance pipeline to detect potential issues using Googleâ€™s Gemini AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbaxrckwbTA7"
      },
      "source": [
        "Choose the Gemini model ID for this notebook from - [click here](https://ai.google.dev/gemini-api/docs/models/gemini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afOy1gQjo7ly"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13fdxZsgp9bE"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import sys\n",
        "from google.colab import auth\n",
        "from google import genai\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.cloud import storage\n",
        "import csv\n",
        "import subprocess\n",
        "from typing import Any\n",
        "import json\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    GoogleSearch,\n",
        "    Part,\n",
        "    Retrieval,\n",
        "    SafetySetting,\n",
        "    Tool,\n",
        "    VertexAISearch,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlUUhBHKpzif"
      },
      "outputs": [],
      "source": [
        "# Authenticate colab notebook.\n",
        "if \"google.colab\" in sys.modules:\n",
        "  auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IwHT3LKNsoCq"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "\n",
        "def read_csv(file_path: str) -\u003e list[str]:\n",
        "  \"\"\"Reads a CSV file and returns its contents as a list.\n",
        "\n",
        "  This function reads the given CSV file, skips the header, and assumes\n",
        "  there is only one column in the CSV. It returns the contents as a list of\n",
        "  strings.\n",
        "\n",
        "  Args:\n",
        "      file_path: The path to the CSV file.\n",
        "\n",
        "  Returns:\n",
        "      The contents of the CSV file as a list of strings.\n",
        "  \"\"\"\n",
        "  data_list = []\n",
        "  with open(file_path, mode='r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      if row:  # Ensure the row is not empty\n",
        "       data_list.append(row[0])  # Assuming there is only one column in the CSV\n",
        "  return data_list\n",
        "\n",
        "\n",
        "def read_json(file_path: str) -\u003e dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Reads a JSON file and returns its contents as a dictionary.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        The parsed JSON content.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as json_file:\n",
        "            return json.load(json_file)\n",
        "    except FileNotFoundError as err:\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\") from err\n",
        "    except json.JSONDecodeError as err:\n",
        "        raise json.JSONDecodeError(f\"Invalid JSON format in file: {file_path}\", doc=str(err.doc), pos=err.pos) from err\n",
        "\n",
        "\n",
        "def convert_bbox_coco_to_xyxy(bbox: list) -\u003e list:\n",
        "    \"\"\"Converts a COCO bounding box format.\n",
        "\n",
        "    Convert [x, y, width, height] to [x1, y1, x2, y2] format.\n",
        "\n",
        "    Args:\n",
        "        bbox: A bounding box in COCO format [x, y, width, height].\n",
        "\n",
        "    Returns:\n",
        "        Converted bounding box in [x1, y1, x2, y2] format.\n",
        "    \"\"\"\n",
        "    x1 = bbox[0]\n",
        "    y1 = bbox[1]\n",
        "    x2 = x1 + bbox[2]  # x1 + width\n",
        "    y2 = y1 + bbox[3]  # y1 + height\n",
        "    return [x1, y1, x2, y2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko7KzR4RryLZ"
      },
      "source": [
        "## GCP Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpZITLLeqHwD"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-001\" # @param {type: \"string\", placeholder: \"[your-model-id]\", isTemplate: true}\n",
        "PROJECT_ID = \"projectidgoeshere\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "# Gemini 2.0 Client - authentication through GCP/Vertex AI\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQbr3rZgt3yX"
      },
      "source": [
        "## Download the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8V0Zz_8vZdf"
      },
      "outputs": [],
      "source": [
        "url = (\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/refs/heads/master/\"\n",
        "    \"official/projects/waste_identification_ml/pre_processing/config/data/45_labels.csv\"\n",
        ")\n",
        "\n",
        "subprocess.run([\"wget\", url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2UpdLNYuLqa"
      },
      "outputs": [],
      "source": [
        "labels = read_csv('45_labels.csv')\n",
        "labels_mapping = {i:j for i,j in enumerate(labels, start=1)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaKfTkEFx7pp"
      },
      "source": [
        "## Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hVh0Jc3y-rq"
      },
      "source": [
        "## Download COCO JSON annotation file \u0026 Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poTMK2gU36Sy"
      },
      "outputs": [],
      "source": [
        "# Download sample image file.\n",
        "image_url = (\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/refs/heads/master/\"\n",
        "    \"official/projects/waste_identification_ml/pre_processing/config/\"\n",
        "    \"sample_images/image_2.png\"\n",
        ")\n",
        "\n",
        "subprocess.run([\"wget\", image_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNKg_Tx14GKN"
      },
      "outputs": [],
      "source": [
        "# Download sample COCO JSON file.\n",
        "json_url = (\n",
        "    \"https://raw.githubusercontent.com/tensorflow/models/refs/heads/master/\"\n",
        "    \"official/projects/waste_identification_ml/pre_processing/config/\"\n",
        "    \"sample_json/gemini_sample.json\"\n",
        ")\n",
        "\n",
        "subprocess.run([\"wget\", json_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YahV2lpgzzRI"
      },
      "outputs": [],
      "source": [
        "# Read COCO JSON file.\n",
        "json_coco_data = read_json('/content/gemini_sample.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgU0mWQXTgX5"
      },
      "outputs": [],
      "source": [
        "## Load an image.\n",
        "image = cv2.imread('/content/image_2.png')\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct3qSKziVRfZ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruFO8m8Lx9QT"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\u003cOBJECTIVE_AND_PERSONA\u003e\n",
        "You're a Object Annotation Data Quality Checker.\n",
        "\n",
        "You will be given 1) an image of a object and 2) the annotation label for the object - please confirm if the annotation label is correct for the object.\n",
        "If it's not correct, please 1) provide reasoning why it's not correct, and 2) provide the correct annotation label from this list of labels: {labels}\n",
        "\n",
        "For context, the object images you will be given are from a waste pile or on a conveyor belt.\n",
        "\n",
        "\u003cOUTPUT_FORMAT\u003e\n",
        "Structure your output as a JSON like the following:\n",
        "(\n",
        "  \"original_label\": [insert original label here],\n",
        "  \"correct\": [insert True or False here],\n",
        "  \"reasoning\": [insert reasoning on why it's correct or not here],\n",
        "  \"correct_label\": [insert correct label or N/A if already correct here]\n",
        ")\n",
        "\"\"\".format(labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m7TnMMKU8pn"
      },
      "outputs": [],
      "source": [
        "for annotation in json_coco_data['annotations']:\n",
        "  annotated_label = labels_mapping[annotation['category_id']]\n",
        "\n",
        "  # Convert bbox formatfrom x, y, width, height to x1, y1, x2, y2 format.\n",
        "  x1, y1, x2, y2 = convert_bbox_coco_to_xyxy(annotation['bbox'])\n",
        "\n",
        "  # Get the image of an object using bbox.\n",
        "  cropped_image_rgb_coords = image_rgb[y1:y2, x1:x2]\n",
        "  cropped_image = Image.fromarray(cropped_image_rgb_coords)\n",
        "  cropped_image.thumbnail([256,256])\n",
        "\n",
        "\n",
        "  print(f\"Original Label: {annotated_label}\")\n",
        "  plt.imshow(cropped_image)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        cropped_image,\n",
        "        prompt + \"\\nAnnotation Label: \" + annotated_label\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFc2v21-Kf-C"
      },
      "outputs": [],
      "source": [
        "# Extract generated text\n",
        "if response.candidates:\n",
        "    raw_text = response.candidates[0].content.parts[0].text  # Get the text output\n",
        "\n",
        "    # Remove the triple backticks and language identifier (`json`)\n",
        "    json_string = re.sub(r\"```json\\n|\\n```\", \"\", raw_text).strip()\n",
        "\n",
        "    try:\n",
        "        response_json = json.loads(json_string)  # Convert to dictionary\n",
        "        print(response_json)  # Print parsed JSON\n",
        "\n",
        "        # Access specific fields if needed\n",
        "        original_label = response_json.get(\"original_label\")\n",
        "        correct = response_json.get(\"correct\")\n",
        "        reasoning = response_json.get(\"reasoning\")\n",
        "        correct_label = response_json.get(\"correct_label\")\n",
        "\n",
        "        print(f\"Original Label: {original_label}\")\n",
        "        print(f\"Correct: {correct}\")\n",
        "        print(f\"Reasoning: {reasoning}\")\n",
        "        print(f\"Correct Label: {correct_label}\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Failed to decode JSON. Raw text:\", json_string)\n",
        "else:\n",
        "    print(\"No candidates returned in the response.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
