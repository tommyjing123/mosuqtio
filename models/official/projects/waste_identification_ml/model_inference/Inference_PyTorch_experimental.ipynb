{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtzVZpUyxS5B"
      },
      "source": [
        "# Waste identification with instance segmentation in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTrqWFRdxYyJ"
      },
      "source": [
        "Welcome to the Instance Segmentation Colab! This notebook will take you through the steps of running an \"out-of-the-box\" Mask RCNN Instance Segmentation model on image from Detectron2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Gxj-CPxnFe"
      },
      "source": [
        "To finish this task, a proper path for the model and a single image needs to be provided. The path to the labels on which the models are trained is in the waste_identification_ml directory inside the Tensorflow Model Garden repository. The label files are inferred automatically for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgJKrYHEyAEv"
      },
      "source": [
        "## RESTART the colab notebook after installing packages of Detectron2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXxxDT_QW2mR"
      },
      "outputs": [],
      "source": [
        "# Clone the Detectron2 repository and install the required packages.\n",
        "# Relax as installing packages might take a while.\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCWF8h6TuNqZ"
      },
      "outputs": [],
      "source": [
        "# Install supervision package for the postprocessing of output results\n",
        "# from Detectron2 Mask RCNN model.\n",
        "!pip install -q supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1oMgVZj4n9n"
      },
      "source": [
        "## Clone the TF Model Garden repo where the waste identification project is located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHm3oznC4uBe"
      },
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models 2\u003e/dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckQUcFtq1P3w"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdgIDnYe1dgv"
      },
      "outputs": [],
      "source": [
        "# Third-Party Imports\n",
        "import csv\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "\n",
        "# Detectron2 Imports\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.structures import Instances, Boxes\n",
        "from detectron2.data.catalog import Metadata\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# Setup Detectron2 Logger\n",
        "setup_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R48IuhsN__vG"
      },
      "outputs": [],
      "source": [
        "#@title Utilities\n",
        "\n",
        "\n",
        "def convert_detections_to_instances(\n",
        "    outputs: dict,\n",
        "    image_size: tuple[int, int] = (1024, 1024),\n",
        "    nms_threshold: float = 0.8,\n",
        "    class_agnostic: bool = True\n",
        ") -\u003e dict[str, Instances]:\n",
        "    \"\"\"Convert Detectron2 model outputs to an Instances object with Non-Maximum Suppression (NMS) applied.\n",
        "\n",
        "    Args:\n",
        "        outputs: Detectron2 model output containing instance predictions.\n",
        "        image_size: Image dimensions (height, width).\n",
        "        nms_threshold: Non-Maximum Suppression (NMS) threshold.\n",
        "        class_agnostic: Whether NMS should be applied in a class-agnostic manner.\n",
        "\n",
        "    Returns:\n",
        "        Reformatted Detectron2 output as {\"instances\": Instances}.\n",
        "    \"\"\"\n",
        "    # Apply NMS and convert to supervision Detections format\n",
        "    detections = (\n",
        "        sv.Detections.from_detectron2(outputs)\n",
        "        .with_nms(threshold=nms_threshold, class_agnostic=class_agnostic)\n",
        "    )\n",
        "\n",
        "    # Convert extracted values to PyTorch tensors\n",
        "    bboxes = torch.tensor(detections.xyxy, dtype=torch.float32)\n",
        "    scores = torch.tensor(detections.confidence, dtype=torch.float32)\n",
        "    classes = torch.tensor(detections.class_id, dtype=torch.int64)\n",
        "\n",
        "    # Create an Instances object\n",
        "    output_instances = Instances(image_size)\n",
        "    output_instances.set(\"pred_boxes\", Boxes(bboxes))\n",
        "    output_instances.set(\"scores\", scores)\n",
        "    output_instances.set(\"pred_classes\", classes)\n",
        "\n",
        "    # Add masks if available\n",
        "    if detections.mask is not None:\n",
        "        masks = torch.tensor(detections.mask, dtype=torch.uint8)\n",
        "        output_instances.set(\"pred_masks\", masks)\n",
        "\n",
        "    return {\"instances\": output_instances}\n",
        "\n",
        "\n",
        "def read_csv(file_path: str) -\u003e list[str]:\n",
        "  \"\"\"Reads a CSV file and returns its contents as a list.\n",
        "\n",
        "  This function reads the given CSV file, skips the header, and assumes\n",
        "  there is only one column in the CSV. It returns the contents as a list of\n",
        "  strings.\n",
        "\n",
        "  Args:\n",
        "      file_path: The path to the CSV file.\n",
        "\n",
        "  Returns:\n",
        "      The contents of the CSV file as a list of strings.\n",
        "  \"\"\"\n",
        "  data_list = []\n",
        "  with open(file_path, 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      data_list.append(row[0])\n",
        "  return data_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Q3y2r04e57"
      },
      "source": [
        "## Import and load the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2426m2L41Ny"
      },
      "outputs": [],
      "source": [
        "LABELS_PATH = (\n",
        "    'models/official/projects/waste_identification_ml/pre_processing/'\n",
        "    'config/data/45_labels.csv'\n",
        ")\n",
        "\n",
        "labels = read_csv(LABELS_PATH)\n",
        "\n",
        "my_metadata = Metadata()\n",
        "my_metadata.set(thing_classes=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWQkSqN_3aTP"
      },
      "source": [
        "## Import Detectron2 Mask RCNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P64IPCT3fsr"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "wget https://storage.googleapis.com/tf_model_garden/vision/\\\n",
        "waste_identification_ml/Detectron2_Jan2025_1024_1024.zip\n",
        "\n",
        "unzip Detectron2_Jan2025_1024_1024.zip \u003e /dev/null 2\u003e\u00261"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ8MSkWh5uLG"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVxcxg7GYQ1U"
      },
      "outputs": [],
      "source": [
        "# Initialize the Detectron2 configuration object\n",
        "cfg = get_cfg()\n",
        "\n",
        "# Load the model configuration from a YAML file.\n",
        "cfg.merge_from_file(\"config.yaml\")\n",
        "\n",
        "# Set the confidence threshold.\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "# Specify the path to the trained model weights.\n",
        "cfg.MODEL.WEIGHTS = \"model_final.pth\"\n",
        "\n",
        "# Create a predictor object using the configured model.\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYQJfdL46GPD"
      },
      "source": [
        "## Import and load an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKjCF3KY6IUz"
      },
      "outputs": [],
      "source": [
        "# Path to a sample image stored in the repo.\n",
        "IMAGES_FOR_TEST = {\n",
        "    'Image1': (\n",
        "        'models/official/projects/waste_identification_ml/pre_processing/'\n",
        "        'config/sample_images/image_2.png'\n",
        "    )\n",
        "}\n",
        "\n",
        "# The model is trained on 1024 x 1024 image dimensions\n",
        "HEIGHT = 1024\n",
        "WIDTH = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIsvxs4e884I"
      },
      "outputs": [],
      "source": [
        "original_image = cv2.imread(IMAGES_FOR_TEST['Image1'])\n",
        "original_height, original_width = original_image.shape[:2]\n",
        "\n",
        "resized_image = cv2.resize(\n",
        "    original_image,\n",
        "    (WIDTH, HEIGHT),\n",
        "    interpolation=cv2.INTER_AREA\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ney4CQXu6gvN"
      },
      "source": [
        "## Perform prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQASihEu6icr"
      },
      "outputs": [],
      "source": [
        "outputs = predictor(resized_image)\n",
        "outputs = convert_detections_to_instances(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwehoMHn7Ruw"
      },
      "source": [
        "## Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keAsVmTy9I_4"
      },
      "outputs": [],
      "source": [
        "# Extract the predicted instances\n",
        "instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "# Rescale bounding boxes back to the original image size\n",
        "scale_x = original_width / WIDTH\n",
        "scale_y = original_height / HEIGHT\n",
        "instances.pred_boxes.scale(scale_x, scale_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAdEtkhQ98Z9"
      },
      "outputs": [],
      "source": [
        "# Resize masks to match the original image size\n",
        "if instances.has(\"pred_masks\"):\n",
        "    pred_masks = instances.pred_masks.numpy()  # Convert to NumPy array\n",
        "    resized_masks = []\n",
        "\n",
        "    for mask in pred_masks:\n",
        "        resized_mask = cv2.resize(\n",
        "            mask.astype(\"uint8\"),\n",
        "            (original_width, original_height),\n",
        "            interpolation=cv2.INTER_NEAREST\n",
        "        )\n",
        "        resized_masks.append(resized_mask)\n",
        "\n",
        "    instances.pred_masks = torch.tensor(resized_masks, dtype=torch.uint8)\n",
        "\n",
        "# Initialize the visualizer with the original image\n",
        "visualizer = Visualizer(\n",
        "    img_rgb=original_image,  # Use the original image\n",
        "    metadata=my_metadata,  # Metadata containing class labels, colors, etc.\n",
        "    scale=1  # Scale factor for visualization\n",
        ")\n",
        "\n",
        "# Draw predictions on the original image\n",
        "visualized_image = visualizer.draw_instance_predictions(instances).get_image()\n",
        "\n",
        "# Convert BGR to RGB for correct visualization in Matplotlib\n",
        "visualized_image = visualized_image[:, :, ::-1]\n",
        "\n",
        "# Display the final image with predictions overlaid on the original image\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(visualized_image)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [
        {
          "file_id": "1A48TxIzVaHghg_ZYAxIgjv3uL7XhQEtR",
          "timestamp": 1740088542918
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
